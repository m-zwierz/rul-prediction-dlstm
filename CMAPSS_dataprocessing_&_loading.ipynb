{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc7gq__pn6ot",
        "outputId": "09ddf10c-409d-4506-9b73-690ed363a05b"
      },
      "outputs": [],
      "source": [
        "# Instalacja PyTorch Lightning\n",
        "# !pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A379bRHcn7pe",
        "outputId": "56704917-225e-417c-818c-61ee7eb97e9d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1. System i Dane\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 2. PyTorch (Silnik)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# 3. PyTorch Lightning (Trener)\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# 4. Preprocessing\n",
        "# To jedyny element z zewnątrz, który zostawiamy, bo ręczne pisanie\n",
        "# normalizacji danych (skalowania do 0-1) to strata czasu i ryzyko błędu.\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import GroupShuffleSplit # ### NOWE: Potrzebne do podziału silników\n",
        "\n",
        "\n",
        "# Ustawienie ziarna losowości dla powtarzalności\n",
        "pl.seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCuPUXbXoBXJ",
        "outputId": "f3742ebc-7d5f-4ae3-b87d-eaab80217734"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'CMAPSSData' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/edwardzjl/CMAPSSData.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CMAPSS_Preprocessor:\n",
        "    def __init__(self, data_path, sequence_length=30, alpha=0.25, max_rul=125):\n",
        "        self.data_path = data_path #ściezka do pliku\n",
        "        self.sequence_length = sequence_length #długość okna czasowego\n",
        "        self.alpha = alpha  # Współczynnik wygładzania z artykułu\n",
        "        self.max_rul = max_rul # Przycinanie RUL (Piecewise Linear)\n",
        "\n",
        "        # Definicja kolumn tablicy na dane\n",
        "        self.index_cols = ['unit_nr', 'time_cycles']\n",
        "        self.setting_cols = ['os_1', 'os_2', 'os_3']\n",
        "        \n",
        "        # ### ZMIANA START: Definicja wszystkich sensorów oraz tych wybranych w artykule ###\n",
        "        self.all_sensor_cols = ['s' + str(i) for i in range(1, 22)] # Wszystkie 21 sensorów (do wczytania i wygładzenia)\n",
        "        \n",
        "        # Zgodnie z artykułem dla FD001 wybrano tylko te sensory (CSC > 0.75):\n",
        "        # S2, S3, S4, S7, S8, S11, S12, S13, S15, S17, S20, S21\n",
        "        self.selected_sensors = ['s2', 's3', 's4', 's7', 's8', 's11', \n",
        "                                 's12', 's13', 's15', 's17', 's20', 's21']\n",
        "        \n",
        "        # Do wczytania używamy wszystkich nazw\n",
        "        self.cols = self.index_cols + self.setting_cols + self.all_sensor_cols\n",
        "        # ### ZMIANA KONIEC ###\n",
        "\n",
        "        # Skaler (będziemy go uczyć tylko na treningu)(?) - normalizacja odczytów z czujników do zakresu 0-1\n",
        "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "    def process(self, file_name='FD001'):\n",
        "        # 1. Wczytanie danych z  plików do dataframes (tabeli)\n",
        "        train_df = pd.read_csv(f'{self.data_path}/train_{file_name}.txt', sep=r'\\s+', header=None, names=self.cols)\n",
        "        test_df = pd.read_csv(f'{self.data_path}/test_{file_name}.txt', sep=r'\\s+', header=None, names=self.cols)\n",
        "        test_rul_df = pd.read_csv(f'{self.data_path}/RUL_{file_name}.txt', sep=r'\\s+', header=None, names=['RUL'])\n",
        "\n",
        "        # 2. Obliczenie etykiet RUL dla treningu\n",
        "        train_df = self._add_rul(train_df, is_test=False)\n",
        "\n",
        "        # 3. Wygładzanie danych (Exponential Smoothing) - WAŻNE!\n",
        "        # ### KOMENTARZ: Wygładzamy wszystkie sensory, zanim odrzucimy te niepotrzebne\n",
        "        train_df = self._smooth_data(train_df)\n",
        "        test_df = self._smooth_data(test_df)\n",
        "\n",
        "        # ### ZMIANA START: Selekcja cech i Normalizacja ###\n",
        "        # Bierzemy TYLKO wybrane sensory (bez ustawień os_*, bo artykuł ich nie używa dla FD001)\n",
        "        feats = self.selected_sensors \n",
        "        \n",
        "        # 4. Normalizacja (Fit na CAŁYM zbiorze treningowym, Transform na obu)\n",
        "        # .fit znajduje max i min w zbiorach feats\n",
        "        self.scaler.fit(train_df[feats])      \n",
        "        train_df[feats] = self.scaler.transform(train_df[feats])  # normalizacja dataframeu treningowego\n",
        "        test_df[feats] = self.scaler.transform(test_df[feats])    # normalizacja dataframeu testowego\n",
        "        # ### ZMIANA KONIEC ###\n",
        "\n",
        "        # ### NOWE START: Podział zbioru treningowego na Train (90) i Val (10) ###\n",
        "        # Artykuł mówi: \"90 engines are randomly chosen for training and 10 for validation\"\n",
        "        splitter = GroupShuffleSplit(n_splits=1, train_size=0.9, random_state=42)\n",
        "        train_idx, val_idx = next(splitter.split(train_df, groups=train_df['unit_nr']))\n",
        "        \n",
        "        real_train_df = train_df.iloc[train_idx].copy() # 90 silników\n",
        "        real_val_df = train_df.iloc[val_idx].copy()     # 10 silników\n",
        "        # ### NOWE KONIEC ###\n",
        "\n",
        "        # 5. Generowanie okien czasowych (Sliding Window)\n",
        "        # ### ZMIANA: Generujemy osobno dla Train i Val ###\n",
        "        X_train, y_train = self._gen_sequence(real_train_df, feats)\n",
        "        X_val, y_val = self._gen_sequence(real_val_df, feats)\n",
        "        \n",
        "        # Uwaga: Dla testu w C-MAPSS zazwyczaj bierze się tylko OSTATNIE okno,\n",
        "        # bo plik RUL_FD001.txt zawiera tylko jedną liczbę dla każdego silnika (RUL na samym końcu).\n",
        "        X_test, y_test = self._gen_test_sequence(test_df, test_rul_df, feats)\n",
        "\n",
        "        # ### ZMIANA: Zwracamy teraz 6 tablic zamiast 4 ###\n",
        "        return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "    def _add_rul(self, df, is_test=False):\n",
        "        # Grupowanie po silniku, znalezienie max cyklu\n",
        "        max_life = df.groupby('unit_nr')['time_cycles'].transform('max')\n",
        "        df['RUL'] = max_life - df['time_cycles']\n",
        "\n",
        "        # Implementacja Piecewise Linear RUL (ucinamy powyżej 125)\n",
        "        df['RUL'] = df['RUL'].clip(upper=self.max_rul)\n",
        "        return df\n",
        "\n",
        "    def _smooth_data(self, df):\n",
        "        # WAŻNE: Musimy grupować po 'unit_nr'!\n",
        "        # Nie możemy pozwolić, by wygładzanie przeniosło się z końca Silnika 1 na początek Silnika 2.\n",
        "        \n",
        "        # ### ZMIANA: Używamy self.all_sensor_cols zamiast self.sensor_cols ###\n",
        "        df[self.all_sensor_cols] = df.groupby('unit_nr')[self.all_sensor_cols].transform(     #wg Gemini .ewm.mean zrobi to samo co wzór na wygładzanie z artykułu\n",
        "            lambda x: x.ewm(alpha=self.alpha, adjust=False).mean()\n",
        "        )\n",
        "        return df\n",
        "\n",
        "    def _gen_sequence(self, df, feature_cols):\n",
        "        X, y = [], []\n",
        "        data_array = df[feature_cols].values    # data_array: Czysta macierz liczb [Liczba cykli, 12 sensorów]\n",
        "        target_array = df['RUL'].values     # target_array: Wektor RUL\n",
        "        unit_ids = df['unit_nr'].values\n",
        "\n",
        "        # Iterujemy, ale musimy uważać, żeby okno nie \"przeskoczyło\" między silnikami\n",
        "        for i in range(len(df) - self.sequence_length):\n",
        "            # Sprawdzamy czy okno mieści się w JEDNYM silniku\n",
        "            if unit_ids[i] == unit_ids[i + self.sequence_length]: #id silnika takie same na początku i końcu sekwencji\n",
        "                # Dodajemy okno\n",
        "                X.append(data_array[i : i + self.sequence_length]) \n",
        "                # Dodajemy cel (RUL w ostatnim kroku tego okna)\n",
        "                y.append(target_array[i + self.sequence_length - 1])\n",
        "\n",
        "        # np.array(X) ma wymiar: [N, T, 12]\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def _gen_test_sequence(self, test_df, truth_df, feature_cols):\n",
        "        X, y = [], []\n",
        "        # Dla zbioru testowego bierzemy tylko OSTATNIE cykle każdego silnika\n",
        "        # I przypisujemy mu prawdziwy RUL z pliku RUL_FD001.txt\n",
        "\n",
        "        true_ruls = truth_df['RUL'].values   #truth_df Wymiar: [100 wierszy, 1 kolumna]\n",
        "\n",
        "        for unit_id in test_df['unit_nr'].unique():     #.unique usuwa wielokrotne id\n",
        "            # Wyciągamy dane jednego silnika\n",
        "            temp_df = test_df[test_df['unit_nr'] == unit_id]\n",
        "\n",
        "            if len(temp_df) >= self.sequence_length:\n",
        "                # Bierzemy ostatnie 'sequence_length' cykli\n",
        "                window = temp_df[feature_cols].values[-self.sequence_length:]\n",
        "                X.append(window)\n",
        "                # Bierzemy prawdziwy RUL (indeks unit_id-1, bo silniki są od 1, tablica od 0)\n",
        "                y.append(true_ruls[unit_id - 1])\n",
        "\n",
        "        return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CMAPSSDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, data_path='CMAPSSData', batch_size=10, sequence_length=30):\n",
        "        super().__init__()\n",
        "        self.data_path = data_path\n",
        "        self.batch_size = batch_size # Wg artykułu batch=10\n",
        "        self.sequence_length = sequence_length\n",
        "        self.preprocessor = CMAPSS_Preprocessor(data_path, sequence_length)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Tu dzieje się cała magia przygotowania danych\n",
        "        # ### ZMIANA: Odbieramy 6 zmiennych (Train, Val, Test) ###\n",
        "        X_train_np, y_train_np, X_val_np, y_val_np, X_test_np, y_test_np = self.preprocessor.process('FD001')\n",
        "\n",
        "        # Konwersja Numpy -> PyTorch Tensor\n",
        "        self.train_X = torch.tensor(X_train_np, dtype=torch.float32)\n",
        "        self.train_y = torch.tensor(y_train_np, dtype=torch.float32).unsqueeze(1) # [N] -> [N, 1]\n",
        "\n",
        "        # ### NOWE: Tensory walidacyjne ###\n",
        "        self.val_X = torch.tensor(X_val_np, dtype=torch.float32)\n",
        "        self.val_y = torch.tensor(y_val_np, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "        self.test_X = torch.tensor(X_test_np, dtype=torch.float32)\n",
        "        self.test_y = torch.tensor(y_test_np, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "        print(f\"Dane przygotowane!\")\n",
        "        print(f\"Trening (90 silników): {self.train_X.shape}\") \n",
        "        print(f\"Walidacja (10 silników): {self.val_X.shape}\") \n",
        "        print(f\"Test (100 silników, ostatnie okna): {self.test_X.shape}\") \n",
        "\n",
        "    def train_dataloader(self):\n",
        "        # Shuffle=True jest kluczowe dla treningu!\n",
        "        dataset = torch.utils.data.TensorDataset(self.train_X, self.train_y)\n",
        "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        # ### ZMIANA: Używamy teraz prawdziwego zbioru walidacyjnego (10 wydzielonych silników) ###\n",
        "        # Używamy shuffle=False dla walidacji\n",
        "        dataset = torch.utils.data.TensorDataset(self.val_X, self.val_y)\n",
        "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=False)\n",
        "    \n",
        "    # ### NOWE: Dodajemy loader dla zbioru testowego (do sprawdzenia ostatecznych wyników po treningu) ###\n",
        "    def test_dataloader(self):\n",
        "        dataset = torch.utils.data.TensorDataset(self.test_X, self.test_y)\n",
        "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCqVDxTSns9C",
        "outputId": "e60be40f-e5bf-4c10-c9cc-76fa11a3ffe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dane przygotowane!\n",
            "Trening (90 silników): torch.Size([15757, 30, 12])\n",
            "Walidacja (10 silników): torch.Size([1874, 30, 12])\n",
            "Test (100 silników, ostatnie okna): torch.Size([100, 30, 12])\n",
            "\n",
            "--- Sprawdzenie Batcha ---\n",
            "Wymiary wejścia (X): torch.Size([10, 30, 12])\n",
            "Wymiary etykiet (y): torch.Size([10, 1])\n",
            "\n",
            "Przykładowy RUL z batcha: 104.0\n"
          ]
        }
      ],
      "source": [
        "# 1. Inicjalizacja DataModule\n",
        "dm = CMAPSSDataModule(batch_size=10, sequence_length=30)\n",
        "\n",
        "# 2. Uruchomienie setup (wczytanie i przetworzenie)\n",
        "dm.setup()\n",
        "\n",
        "# 3. Sprawdzenie jednej paczki danych\n",
        "# Pobieramy jeden batch z loadera\n",
        "x_batch, y_batch = next(iter(dm.train_dataloader()))\n",
        "\n",
        "print(\"\\n--- Sprawdzenie Batcha ---\")\n",
        "print(f\"Wymiary wejścia (X): {x_batch.shape}\")\n",
        "# Powinno być: torch.Size([10, 30, 24]) -> 10 próbek, 30 cykli, 24 cechy\n",
        "print(f\"Wymiary etykiet (y): {y_batch.shape}\")\n",
        "# Powinno być: torch.Size([10, 1]) -> 10 wyników RUL\n",
        "\n",
        "print(\"\\nPrzykładowy RUL z batcha:\", y_batch[0].item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dane przygotowane!\n",
            "Trening (90 silników): torch.Size([13957, 50, 12])\n",
            "Walidacja (10 silników): torch.Size([1674, 50, 12])\n",
            "Test (100 silników, ostatnie okna): torch.Size([93, 50, 12])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name      | Type    | Params | Mode  | FLOPs\n",
            "------------------------------------------------------\n",
            "0 | lstm      | LSTM    | 368 K  | train | 0    \n",
            "1 | fc        | Linear  | 101    | train | 0    \n",
            "2 | criterion | MSELoss | 0      | train | 0    \n",
            "------------------------------------------------------\n",
            "368 K     Trainable params\n",
            "0         Non-trainable params\n",
            "368 K     Total params\n",
            "1.476     Total estimated model params size (MB)\n",
            "3         Modules in train mode\n",
            "0         Modules in eval mode\n",
            "0         Total Flops\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d08a3a0d877745bdb774d9fea6366681",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marci\\miniconda3\\envs\\gsn_laby\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "c:\\Users\\marci\\miniconda3\\envs\\gsn_laby\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82b5e19628944b49882998451461e5c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9843379a39b54600904f7d1b01a84b94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Metric val_rmse improved. New best score: 37.298\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b84115e70ea4a35a31e1c984716f642",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Metric val_rmse improved by 0.193 >= min_delta = 0.001. New best score: 37.105\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93e9c7b748e34933a1c46540c0e97a7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Metric val_rmse improved by 0.048 >= min_delta = 0.001. New best score: 37.057\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57935c3c0b224d1c84459441263e0752",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11302b0b53aa44d099991296f71c6531",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Metric val_rmse improved by 0.050 >= min_delta = 0.001. New best score: 37.007\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5a27b02229b40d285c22929e87e087e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad3db2683fe141a498a52d530c5e9b6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bd92ffe99524a35a2686e5511549202",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60f2b1e0b2b34d11a6c49c339f30a4dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Monitored metric val_rmse did not improve in the last 4 records. Best score: 37.007. Signaling Trainer to stop.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uruchamianie testu na najlepszym modelu...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Restoring states from the checkpoint path at c:\\Users\\marci\\Documents\\projects\\rul-prediction-dlstm\\lightning_logs\\version_3\\checkpoints\\best-dlstm-epoch=4-val_rmse=37.01.ckpt\n",
            "c:\\Users\\marci\\miniconda3\\envs\\gsn_laby\\Lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:73: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Loaded model weights from the checkpoint at c:\\Users\\marci\\Documents\\projects\\rul-prediction-dlstm\\lightning_logs\\version_3\\checkpoints\\best-dlstm-epoch=4-val_rmse=37.01.ckpt\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dane przygotowane!\n",
            "Trening (90 silników): torch.Size([13957, 50, 12])\n",
            "Walidacja (10 silników): torch.Size([1674, 50, 12])\n",
            "Test (100 silników, ostatnie okna): torch.Size([93, 50, 12])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marci\\miniconda3\\envs\\gsn_laby\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "306e1ceb252a437aa4b5194fa944425f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        test_rmse            40.68370819091797\n",
            "       test_score            1364.87158203125\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'test_rmse': 40.68370819091797, 'test_score': 1364.87158203125}]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import pytorch_lightning as pl\n",
        "# from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "class DLSTMRegressor(pl.LightningModule):\n",
        "    # ### ZMIANA: Domyślny input_size ustawiony na 12 (zgodnie z nowym pre-processingiem)\n",
        "    def __init__(self, input_size=12, hidden_size=100, num_layers=5, dropout=0.7, learning_rate=0.001):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters() \n",
        "\n",
        "        # Definicja architektury DLSTM zgodnie z artykułem\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout, \n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Warstwa wyjściowa\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = out[:, -1, :] # Ostatni krok czasowy\n",
        "        rul_prediction = self.fc(out)\n",
        "        return rul_prediction\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.criterion(y_hat, y)\n",
        "        \n",
        "        # Logowanie metryk (Czysty pasek: on_step=False)\n",
        "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        \n",
        "        loss = self.criterion(y_hat, y)\n",
        "        rmse = torch.sqrt(loss)\n",
        "        \n",
        "        # Obliczenie metryki Score\n",
        "        h = y_hat - y\n",
        "        score1 = torch.exp(-h[h < 0] / 13) - 1\n",
        "        score2 = torch.exp(h[h >= 0] / 10) - 1\n",
        "        score = torch.sum(score1) + torch.sum(score2)\n",
        "        \n",
        "        # ### ZMIANA: Dodano on_step=False, on_epoch=True dla czystości logów\n",
        "        self.log('val_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log('val_rmse', rmse, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log('val_score', score, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    # ### NOWE: Dodano test_step, aby policzyć ostateczny wynik na zbiorze testowym (Tabela 3 w artykule)\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.criterion(y_hat, y)\n",
        "        rmse = torch.sqrt(loss)\n",
        "        h = y_hat - y\n",
        "        score = torch.sum(torch.exp(-h[h < 0] / 13) - 1) + torch.sum(torch.exp(h[h >= 0] / 10) - 1)\n",
        "        \n",
        "        self.log('test_rmse', rmse, on_epoch=True)\n",
        "        self.log('test_score', score, on_epoch=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
        "\n",
        "\n",
        "# --- KONFIGURACJA TRENINGU ---\n",
        "\n",
        "# 1. Dane\n",
        "dm = CMAPSSDataModule(batch_size=10, sequence_length=50) \n",
        "\n",
        "# 2. Model\n",
        "# ### ZMIANA: input_size=12 (Bo wybraliśmy 12 sensorów z artykułu)\n",
        "model = DLSTMRegressor(\n",
        "    input_size=12,   \n",
        "    hidden_size=100, \n",
        "    num_layers=5,    \n",
        "    dropout=0.7,     \n",
        "    learning_rate=0.001 \n",
        ")\n",
        "\n",
        "# 3. Callbacki (Checkpoint + EarlyStopping)\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_rmse', \n",
        "    mode='min', \n",
        "    save_top_k=1, \n",
        "    filename='best-dlstm-{epoch}-{val_rmse:.2f}'\n",
        ")\n",
        "\n",
        "# ### ZALECANE: Dodaj EarlyStopping, żeby nie czekać 1000 epok, jeśli model przestanie się uczyć\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor=\"val_rmse\", \n",
        "    min_delta=0.001, \n",
        "    patience=4, # Jeśli przez 20 epok wynik się nie poprawi, stop\n",
        "    verbose=True, \n",
        "    mode=\"min\"\n",
        ")\n",
        "\n",
        "# 4. Trener\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=15,               # ### ZMIANA: 1000 epok zgodnie z Tabelą 2 w artykule\n",
        "    accelerator=\"auto\",       \n",
        "    callbacks=[checkpoint_callback, early_stop_callback], # Dodano early stopping\n",
        "    log_every_n_steps=10\n",
        ")\n",
        "\n",
        "# 5. Start\n",
        "trainer.fit(model, dm)\n",
        "\n",
        "# 6. Testowanie (To da wynik porównywalny z Tabelą 3 artykułu)\n",
        "print(\"Uruchamianie testu na najlepszym modelu...\")\n",
        "trainer.test(model, ckpt_path=\"best\", datamodule=dm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # import torch\n",
        "# # import torch.nn as nn\n",
        "# # import torch.nn.functional as F\n",
        "# # import pytorch_lightning as pl\n",
        "\n",
        "# class DLSTMRegressor(pl.LightningModule):\n",
        "#     def __init__(self, input_size=24, hidden_size=100, num_layers=5, dropout=0.7, learning_rate=0.001):\n",
        "#         super().__init__()\n",
        "#         self.save_hyperparameters() # Zapisuje parametry do self.hparams\n",
        "\n",
        "#         # Definicja architektury DLSTM zgodnie z artykułem\n",
        "#         # input_size=24 (3 ustawienia + 21 czujników)\n",
        "#         # batch_first=True, bo nasze dane mają kształt (Batch, Seq, Features)\n",
        "#         self.lstm = nn.LSTM(\n",
        "#             input_size=input_size,\n",
        "#             hidden_size=hidden_size,\n",
        "#             num_layers=num_layers,\n",
        "#             dropout=dropout, \n",
        "#             batch_first=True\n",
        "#         )\n",
        "\n",
        "#         # Warstwa wyjściowa (Fully Connected) - mapuje wyjście LSTM na pojedynczą wartość RUL\n",
        "#         self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "#         # Funkcja straty (MSE)\n",
        "#         self.criterion = nn.MSELoss()\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # x shape: (Batch, Sequence_Length, Features)\n",
        "        \n",
        "#         # Przejście przez warstwy LSTM\n",
        "#         # out shape: (Batch, Sequence_Length, Hidden_Size)\n",
        "#         # _ (hidden states) - ignorujemy\n",
        "#         out, _ = self.lstm(x)\n",
        "        \n",
        "#         # Bierzemy wyjście z OSTATNIEGO kroku czasowego dla każdej próbki w batchu\n",
        "#         # Many-to-One architecture\n",
        "#         out = out[:, -1, :] \n",
        "        \n",
        "#         # Przejście przez warstwę liniową\n",
        "#         rul_prediction = self.fc(out)\n",
        "#         return rul_prediction\n",
        "\n",
        "#     def training_step(self, batch, batch_idx):\n",
        "#         x, y = batch\n",
        "#         y_hat = self(x)\n",
        "#         loss = self.criterion(y_hat, y)\n",
        "        \n",
        "#         # Logowanie metryk\n",
        "#         self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
        "#         return loss\n",
        "\n",
        "#     def validation_step(self, batch, batch_idx):\n",
        "#         x, y = batch\n",
        "#         y_hat = self(x)\n",
        "        \n",
        "#         # 1. Obliczenie RMSE (pierwiastek z MSE)\n",
        "#         loss = self.criterion(y_hat, y)\n",
        "#         rmse = torch.sqrt(loss)\n",
        "        \n",
        "#         # 2. Obliczenie metryki Score (wg wzoru z artykułu/C-MAPSS)\n",
        "#         # h = (Predicted - Real)\n",
        "#         h = y_hat - y\n",
        "        \n",
        "#         # Jeśli h < 0 (wczesna predykcja): exp(-h/13) - 1\n",
        "#         # Jeśli h >= 0 (późna predykcja - groźna): exp(h/10) - 1\n",
        "#         score1 = torch.exp(-h[h < 0] / 13) - 1\n",
        "#         score2 = torch.exp(h[h >= 0] / 10) - 1\n",
        "#         score = torch.sum(score1) + torch.sum(score2)\n",
        "        \n",
        "#         self.log('val_loss', loss, prog_bar=True)\n",
        "#         self.log('val_rmse', rmse, prog_bar=True)\n",
        "#         self.log('val_score', score, prog_bar=True)\n",
        "        \n",
        "#         return loss\n",
        "\n",
        "#     def configure_optimizers(self):\n",
        "#         # Optymalizator Adam (zgodnie z artykułem)\n",
        "#         return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dane przygotowane!\n",
            "Trening (90 silników): torch.Size([13957, 50, 12])\n",
            "Walidacja (10 silników): torch.Size([1674, 50, 12])\n",
            "Test (100 silników, ostatnie okna): torch.Size([93, 50, 12])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name      | Type    | Params | Mode  | FLOPs\n",
            "------------------------------------------------------\n",
            "0 | lstm      | LSTM    | 368 K  | train | 0    \n",
            "1 | fc        | Linear  | 101    | train | 0    \n",
            "2 | criterion | MSELoss | 0      | train | 0    \n",
            "------------------------------------------------------\n",
            "368 K     Trainable params\n",
            "0         Non-trainable params\n",
            "368 K     Total params\n",
            "1.476     Total estimated model params size (MB)\n",
            "3         Modules in train mode\n",
            "0         Modules in eval mode\n",
            "0         Total Flops\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9e78758d5264b4198eee9190d0e35cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marci\\miniconda3\\envs\\gsn_laby\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "c:\\Users\\marci\\miniconda3\\envs\\gsn_laby\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ba08380a7e845cca0bb513459e447bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0491420262546dbad8e71415fb4a9dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91b3d3dd1f104af6b2e88ca8f45cf8b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8dcf9540cbf4b9babfe122f30282543",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0905dcfc9ca848f0ada30a2ec1790378",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e73c2fd3ecb2463e84cb558850293cff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d805912633d84ca2b804479bd5e31e66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea57b8cdc8b640ceb4fc0d5d18d0c8a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b67dcd8f45f64f3e98e37a451d2067bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5137a65ea9284aa590d86c01023cf578",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "307f632352bf4133add9660f6c1ada51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b49111cd863746ebb41d86de332b50b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "faf2286d70a94d868fcba57d0e578f95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3deab8934a714ab0adefc0f7215828ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "154cfbc11d0e4488a96d4a5c30a8fbf0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca50429a847949c988d8d8b43664f3c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7e9b8c741d04589887792d68cc1580a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abce9efe40124707a1821cf540b6a108",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "933e70a741e1483983d979e63d1b1a14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d9de8a5c55047b2925480ed5555262a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f867eb94336547beaf977da0dad36736",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f76cb99e5bb44da9335df26488ef13f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "984184c32ede44259e990e90677cf947",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8a002b609524b19a5ac2b2be0c07b48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d43c97fb72b406f8c47bc3ddd0ff747",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4026f8eec904a438b69fc5b8461f3eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "680b4ca505c44aa6ac44be8f49904d7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "1",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marci\\miniconda3\\envs\\gsn_laby\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3709: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "# # 1. Konfiguracja danych\n",
        "# # Zmieniamy sequence_length na 50, zgodnie z Twoją analizą literatury [11]\n",
        "# # Domyślnie w klasie było 30, ale DataModule jest elastyczny.\n",
        "# dm = CMAPSSDataModule(batch_size=10, sequence_length=50) \n",
        "\n",
        "# # 2. Inicjalizacja modelu DLSTM\n",
        "# # Parametry zgodne z \"najlepszą konfiguracją\" z artykułu (Tabela 1 i sekcja 3.4)\n",
        "# model = DLSTMRegressor(\n",
        "#     input_size=12,   # Liczba cech (z Twojego pre-processora)\n",
        "#     hidden_size=100, # \n",
        "#     num_layers=5,    # \n",
        "#     dropout=0.7,     # \n",
        "#     learning_rate=0.001 # Typowa wartość dla Adama, artykuł sugeruje 0.001 w Tabeli 2 \n",
        "# )\n",
        "\n",
        "# # 3. Setup Trenera (PyTorch Lightning)\n",
        "# # Ustawiamy max_epochs na np. 100 (artykuł używał 1000, ale na początek wystarczy mniej)\n",
        "# checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "#     monitor='val_rmse', \n",
        "#     mode='min', \n",
        "#     save_top_k=1, \n",
        "#     filename='best-dlstm-{epoch}-{val_rmse:.2f}'\n",
        "# )\n",
        "\n",
        "# trainer = pl.Trainer(\n",
        "#     max_epochs=500,             # Dostosuj wg potrzeb\n",
        "#     accelerator=\"auto\",        # Użyje GPU jeśli dostępne\n",
        "#     callbacks=[checkpoint_callback],\n",
        "#     log_every_n_steps=10\n",
        "# )\n",
        "\n",
        "# # 4. Start Treningu\n",
        "# trainer.fit(model, dm)\n",
        "\n",
        "# # 5. Wyniki walidacji po treningu\n",
        "# print(\"Najlepszy wynik walidacji (RMSE):\", checkpoint_callback.best_model_score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gsn_laby",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
